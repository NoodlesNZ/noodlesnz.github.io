"use strict";(self.webpackChunknoodles=self.webpackChunknoodles||[]).push([[586],{2577:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>u,frontMatter:()=>a,metadata:()=>r,toc:()=>l});var o=n(4848),s=n(8453);const a={title:"Deny access to website, but allow robots.txt"},i=void 0,r={permalink:"/blog/2011/02/15/deny-access-to-website-but-allow-robots-txt",source:"@site/blog/2011-02-15-deny-access-to-website-but-allow-robots-txt.mdx",title:"Deny access to website, but allow robots.txt",description:"I had a problem where Googlebot was indexing a development site, so we locked it down using apache basic http auth. Now Googlebot was being served with a 401 when accessing the site, but because it had no stored robots.txt it was persistently trying to crawl the site.",date:"2011-02-15T00:00:00.000Z",formattedDate:"February 15, 2011",tags:[],readingTime:.53,hasTruncateMarker:!1,authors:[],frontMatter:{title:"Deny access to website, but allow robots.txt"},unlisted:!1,prevItem:{title:"Change CVS path",permalink:"/blog/2011/02/16/change-cvs-path"},nextItem:{title:"unzip 6 for RHEL 5.6",permalink:"/blog/2011/02/15/unzip-6-for-rhel-5-6"}},c={authorsImageUrls:[]},l=[];function h(e){const t={code:"code",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.p,{children:"I had a problem where Googlebot was indexing a development site, so we locked it down using apache basic http auth. Now Googlebot was being served with a 401 when accessing the site, but because it had no stored robots.txt it was persistently trying to crawl the site."}),"\n",(0,o.jsx)(t.p,{children:"Using the following allows anyone to access robots.txt but denies access to the rest of the site:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:'<Directory "/home/username/www">\nAuthUserFile /home/username/.htpasswd\nAuthName "Client Access"\nAuthType Basic\nrequire valid-use  \n\n<Files "robots.txt">\nAuthType Basic\nsatisfy any\n</Files>\n</Directory>\n'})}),"\n",(0,o.jsx)(t.p,{children:"Eventually Googlebot will get the hint and stop indexing the site and we can remove existing content using webmaster tools."})]})}function u(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>r});var o=n(6540);const s={},a=o.createContext(s);function i(e){const t=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),o.createElement(a.Provider,{value:t},e.children)}}}]);